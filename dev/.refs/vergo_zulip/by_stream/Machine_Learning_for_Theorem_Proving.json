{
  "stream": "Machine_Learning_for_Theorem_Proving",
  "message_count": 4,
  "messages": [
    {
      "id": 558062623,
      "sender": "Eric Vergo",
      "content": "Kim Morrison said:\n\nI think Eric Vergo's example above is interesting to look at. There's no doubt that the AIs are already capable of creating repositories with correct (perhaps not interesting) mathematics, checked by Lean.\n\n\nFor what it's worth, I think the math here is interesting. I say this not to put up a stink, but because I think it's relevant to the discussion we are having: Who gets to decide what it means for some piece of mathematics to be interesting?\nTimothy Chow said:\n\nIf we go down the route of publishing a list of recommendations, then we should be mindful that mathematicians hate being told what to do. I'm reminded of the brouhaha that Jaffe and Quinn's article on Theoretical Mathematics generated. Atiyah responded by saying that even though he agreed with much of what they said,  \"I rebel against their general tone and attitude which appears too authoritarian.\" In order to minimize backlash, we will need to avoid sounding too authoritarian.\n\n\nThis is front and center for me. I know that I am a bit of an outsider here, so I would like to take a minor detour and tell you a bit about my background. I do this not to draw attention to it, but to share it with the hope that you fully understand where I am coming from, add some credence to my thoughts, and to give you confidence that I mean what I say. I know who all of you are and given the nature of the conversation I think it makes sense that you know who I am.\nIn August of 2024 I was interviewed on a podcast, where I describe the process of leaving my mechanical engineering career at Apple to pursue mathematics. It is surprising how many things I say during that interview that are relevant to the conversation we are having right now, but the important part is said at the 13:00. (timestamped link at the end of this post, it lasts  5 mins). Additionally, in October of 2023 I wrote “Math is now an Engineering Problem” on my now defunct blog. The critical part of that post is this: \n“Just as Napster was the first warning shot to the music industry that everything was about to change, Sagredo is the first warning shot to mathematicians. \nWhile an incredible achievement, there are numerous opportunities to make this technology significantly more effective; specifically trained LLMs will do a better job of generating error free code, optimization will make the ‘discussion’ between the two subsystems faster, more compute will lead to speed ups. The list goes on. But that list is supplanted in importance by the following observation: everything on that list is a matter of engineering – not mathematics. And, in just the same way the LLM uses the iterative process to ‘engineer’ a proof, we will be able to apply the iterative process to engineer the system itself. What this means is that the ability of this system to produce proofs is a function of our ability to engineer the system, rather than our ability to understand mathematics – it’s engineering all the way down.”\nIs it fair to say that the repo I shared earlier in this thread was made with Sagredo++? I think it is. \nThe core responsibility I had as an engineer was to take product designs/architectures which had been validated at low volume and get the product design refined to the point where it can be put into customers hands. This involved designing things that could be manufactured, sometimes in the many millions of units, while maintaining high quality standards. If my time as an engineer taught me anything, it’s that more is different. Different in a way that is not “we keep finding new corner cases that break the kernel” or “This process is the latest bottleneck in build time, that’s a first”. I mean different in a way that no one can predict, different in a way that simply cannot happen unless you are doing things at scale and have a large number of things interacting. When I looked at the coupling of large language models and formal verification systems, I saw something that could be automated and scaled, which led to that blog post. Based off of what I have seen between then and now, I fully expect the tools to become increasingly powerful. What happens as a result of that is very hard to predict.\nLike a lot of people here, I am drawn to and excited by the exacting and brutal standards that formal verification imposes. What excites me more is the fact that I will get to express my creativity while being grounded by Lean. LLMs will be a part of my workflow moving forward and it’s clear that this is true for others as well. I look forward to developing best practices around this that fully respect the rigor that Lean demands, and to do so in a way that increases accessibility while adhering to open source philosophies. I do not know “how to do this right”, and I don’t think anyone does. But we will figure something out.\nhttps://www.youtube.com/watch?v=-3TZG1NiFKA&t=780s",
      "timestamp": "2026-02-02T11:08:51.510660",
      "stream": "Machine Learning for Theorem Proving",
      "topic": null,
      "url": "https://leanprover.zulipchat.com/#narrow/id/558062623"
    },
    {
      "id": 558327426,
      "sender": "Eric Vergo",
      "content": "Tremendous. Thank you for both requesting the clarifications and working through my explanations. Shared understanding is important and I did a poor job of making that possible. I’d like to build on that and tie up a few loose threads.\nTimothy Chow said:\n\nEric Vergo said:\n\nAre there good arguments against full transparency beyond the overhead added when producing proofs?\n\n\nWhat exactly do you mean by \"full transparency\"? \n\n\nBy full transparency I mean two different things. First, and much less of a concern on my end, are end user mathematicians disclosing the use of “AI” tools, along with the logs and techniques used in doing so. Indeed, it is not the norm now that mathematicians publish failed attempts and time spent on wrong ideas. But I would argue that this is, in part, a function of the fact that doing so has been unavailable to mathematicians because of pragmatic constraints. But, the introduction of these tools significantly reduces the amount of work needed to execute on that, so maybe we should consider it. As others in the thread have noted, people may engage in undesired behavior when disclosing use in AI, and this needs to be taken into account. I don’t have solutions for much of, if anything highlighted here but do mirror the concerns that others have shared.\nThe far greater concern, and the intent of my previous posts, is to push for full transparency from companies who are producing the tools that we are going to use. What I mean by that is this: right now we are relying on the good graces of frontier model makers to have access to things like reasoning traces, a full history of actions taken, outputs, intermediate artifacts, tool calls, logs, etc. There is no guarantee that they will do this in the future, and there are already examples of end users having unexpectedly reduced access to these types of things. I am deliberately not including examples to avoid finger pointing, but a quick search will confirm this. I’m bringing this up to illustrate a point: there are implicit assumptions being made that we will always have the option of inspecting every token involved in producing a proof, and the reality is that the option may not always be there.  I am not making the claim that we should make it the norm that mathematicians share all of their relevant LLM interactions moving forward, but I could imagine a future where it is. Moreover, if the norm settles at a ‘less invasive’ level some may want to still choose to share as much as possible. If that is something we want to enable, we should make that clear now. \nThese companies are anticipating that this technology will allow them to capture trillions of dollars in value over the coming years. We should expect them to act in a way that is rational when evaluated against the incentive structures surrounding them. This is not ascribing malice to their actions, simply observing that they are operating in a competitive, high stakes environment. If we want something that is in tension with what they want, we may have to fight hard for it. \nTimothy Chow said:\n\nThanks for the clarification. Let me clarify what I intended by my \"amusing possibility.\" I had in mind LLM-generated proofs written entirely in natural language that sound highly plausible to a professional mathematician, but which are incorrect in the mathematician's sense: i.e., the proof contains huge gaps or even outright false statements. Emily gave an example (maybe not highly plausible, but at least somewhat plausible to a non-expert) early on in her talk.\n\n\nYou are very welcome. I thought Lean was going to be able to easily insulate itself from the type of things Emily shared, but it might not. \nTimothy Chow said:\n\nYour repo also serves as an important cautionary tale, but of a slightly different kind from what I had in mind.\n\n\nA cautionary tale indeed. Even though they are providing legitimate value, LLM based tools and their outputs need to be treated in an adversarial way. \nTimothy Chow said:\n\nYet another kind of cautionary example would be of seemingly formally verified results that are wrong in a strong sense. If you search for \"maliciously doctored\" in Mark Adams's slides on \"Flyspecking Flyspeck\" then you'll see an example of what I mean. One can also imagining maliciously doctoring GMP or some other infrequently scrutinized section of the trusted code base to create a false proof that builds without errors.\n\n\nThis may not even require the malice of a human pilot, just more reward hacking and someone who is not paying attention or is unaware of what is going on.",
      "timestamp": "2026-02-02T11:08:51.510665",
      "stream": "Machine Learning for Theorem Proving",
      "topic": null,
      "url": "https://leanprover.zulipchat.com/#narrow/id/558327426"
    },
    {
      "id": 558465939,
      "sender": "Eric Vergo",
      "content": "Kim Morrison said:\n\nEric Vergo said:\n\nJust as Napster was the first warning shot to the music industry that everything was about to change, Sagredo is the first warning shot to mathematicians.\n\nThanks for the Sagredo shout-out. :-) I'm glad someone noticed it!\n\nI showed it to so many people and no one 'got it'. I couldn't believe what I was seeing, or peoples lack of reaction. I'm sure you are busy with the modules launch (which looks awesome!), but I do think we should develop the tool you mentioned if/when you get some time. I'd be happy to use this repo and others for some stress testing :)",
      "timestamp": "2026-02-02T11:08:51.510669",
      "stream": "Machine Learning for Theorem Proving",
      "topic": null,
      "url": "https://leanprover.zulipchat.com/#narrow/id/558465939"
    },
    {
      "id": 563840651,
      "sender": "Eric Vergo",
      "content": "Johannes Schmitt said:\n\nEric Vergo This sounds very interesting (will read up on your precise proposal), but please do go ahead with using this as a case study! Very happy to provide any assistance you might need.\n\nGreat, this will take me a day or two and I'll post here when things are ready.",
      "timestamp": "2026-02-02T11:08:51.510674",
      "stream": "Machine Learning for Theorem Proving",
      "topic": null,
      "url": "https://leanprover.zulipchat.com/#narrow/id/563840651"
    }
  ]
}